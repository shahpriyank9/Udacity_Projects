{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Mushrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to classify mushrooms as edible or poisonous by using various Machine Learning Methods. All the code in this notebook is written Python 3.5 . Also library used in this notebook containing Machine Learning methods is sklearn which is an open source library. After classification a small analysis is done on the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Code is in Python 3.5\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "from sklearn import preprocessing # Preprocessing\n",
    "from sklearn import metrics  # For Evaluation\n",
    "import matplotlib.pyplot as plt #For Plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is taken from Kaggle (https://www.kaggle.com )\n",
    "The link for the dataset is as follows:\n",
    "https://www.kaggle.com/uciml/mushroom-classification\n",
    "This dataset includes descriptions of hypothetical samples corresponding to 23 species of\n",
    "gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon\n",
    "Society Field Guide to North American Mushrooms (1981). Each species is identified as definitely\n",
    "edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was\n",
    "combined with the poisonous one. The dataset has features which are entirely categorical in\n",
    "nature. The dataset will be used after being transformed by LabelEncoder or OneHotEncoding.\n",
    "The following describes the columns and its categorical values and what they represent.\n",
    "\n",
    "**Attribute Information**: (**classes**: edible=e, poisonous=p)\n",
    "**cap-shape**: bell=b, conical=c, convex=x ,flat=f, knobbed=k, sunken=s\n",
    "**cap-surface**: fibrous=f, grooves=g, scaly=y, smooth=s\n",
    "**cap-color**: brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w,\n",
    "yellow=y\n",
    "**bruises**: bruises=t, no=f\n",
    "**odor**: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n",
    "**gill-attachment**: attached=a, descending=d, free=f, notched=n\n",
    "**gill-spacing**: close=c, crowded=w, distant=d\n",
    "**gill-size**: broad=b, narrow=n\n",
    "**gill-color**: black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o ,pink=p,\n",
    "purple=u, red=e, white=w, yellow=y\n",
    "**stalk-shape**: enlarging=e, tapering=t\n",
    "**stalk-root**: bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=?\n",
    "**stalk-surface-above-ring**: fibrous=f, scaly=y, silky=k, smooth=s \n",
    "**stalk-surface-below-ring**: fibrous=f, scaly=y, silky=k, smooth=s\n",
    "**stalk-color-above-ring**: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e,\n",
    "white=w, yellow=y\n",
    "**stalk-color-below-ring**: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e,\n",
    "white=w, yellow=y\n",
    "**veil-type**: partial=p, universal=u\n",
    "**veil-color**: brown=n, orange=o, white=w, yellow=y\n",
    "**ring-number**: none=n ,one=o, two=t\n",
    "**ring-type**: cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s,\n",
    "zone=z\n",
    "**spore-print-color**: black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u,\n",
    "white=w, yellow=y\n",
    "**population**: abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y\n",
    "**habitat**: grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color   ...   stalk-surface-below-ring  \\\n",
       "0            c         n          k   ...                          s   \n",
       "1            c         b          k   ...                          s   \n",
       "2            c         b          n   ...                          s   \n",
       "3            c         n          n   ...                          s   \n",
       "4            w         b          k   ...                          s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the dataset \n",
    "raw_data=pd.read_csv('mushrooms.csv')\n",
    "\n",
    "#Display top few rows in the dataset\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Name:  class\n",
      "count     8124\n",
      "unique       2\n",
      "top          e\n",
      "freq      4208\n",
      "Name: class, dtype: object\n",
      "\n",
      "Column Name:  cap-shape\n",
      "count     8124\n",
      "unique       6\n",
      "top          x\n",
      "freq      3656\n",
      "Name: cap-shape, dtype: object\n",
      "\n",
      "Column Name:  cap-surface\n",
      "count     8124\n",
      "unique       4\n",
      "top          y\n",
      "freq      3244\n",
      "Name: cap-surface, dtype: object\n",
      "\n",
      "Column Name:  cap-color\n",
      "count     8124\n",
      "unique      10\n",
      "top          n\n",
      "freq      2284\n",
      "Name: cap-color, dtype: object\n",
      "\n",
      "Column Name:  bruises\n",
      "count     8124\n",
      "unique       2\n",
      "top          f\n",
      "freq      4748\n",
      "Name: bruises, dtype: object\n",
      "\n",
      "Column Name:  odor\n",
      "count     8124\n",
      "unique       9\n",
      "top          n\n",
      "freq      3528\n",
      "Name: odor, dtype: object\n",
      "\n",
      "Column Name:  gill-attachment\n",
      "count     8124\n",
      "unique       2\n",
      "top          f\n",
      "freq      7914\n",
      "Name: gill-attachment, dtype: object\n",
      "\n",
      "Column Name:  gill-spacing\n",
      "count     8124\n",
      "unique       2\n",
      "top          c\n",
      "freq      6812\n",
      "Name: gill-spacing, dtype: object\n",
      "\n",
      "Column Name:  gill-size\n",
      "count     8124\n",
      "unique       2\n",
      "top          b\n",
      "freq      5612\n",
      "Name: gill-size, dtype: object\n",
      "\n",
      "Column Name:  gill-color\n",
      "count     8124\n",
      "unique      12\n",
      "top          b\n",
      "freq      1728\n",
      "Name: gill-color, dtype: object\n",
      "\n",
      "Column Name:  stalk-shape\n",
      "count     8124\n",
      "unique       2\n",
      "top          t\n",
      "freq      4608\n",
      "Name: stalk-shape, dtype: object\n",
      "\n",
      "Column Name:  stalk-root\n",
      "count     8124\n",
      "unique       5\n",
      "top          b\n",
      "freq      3776\n",
      "Name: stalk-root, dtype: object\n",
      "\n",
      "Column Name:  stalk-surface-above-ring\n",
      "count     8124\n",
      "unique       4\n",
      "top          s\n",
      "freq      5176\n",
      "Name: stalk-surface-above-ring, dtype: object\n",
      "\n",
      "Column Name:  stalk-surface-below-ring\n",
      "count     8124\n",
      "unique       4\n",
      "top          s\n",
      "freq      4936\n",
      "Name: stalk-surface-below-ring, dtype: object\n",
      "\n",
      "Column Name:  stalk-color-above-ring\n",
      "count     8124\n",
      "unique       9\n",
      "top          w\n",
      "freq      4464\n",
      "Name: stalk-color-above-ring, dtype: object\n",
      "\n",
      "Column Name:  stalk-color-below-ring\n",
      "count     8124\n",
      "unique       9\n",
      "top          w\n",
      "freq      4384\n",
      "Name: stalk-color-below-ring, dtype: object\n",
      "\n",
      "Column Name:  veil-type\n",
      "count     8124\n",
      "unique       1\n",
      "top          p\n",
      "freq      8124\n",
      "Name: veil-type, dtype: object\n",
      "\n",
      "Column Name:  veil-color\n",
      "count     8124\n",
      "unique       4\n",
      "top          w\n",
      "freq      7924\n",
      "Name: veil-color, dtype: object\n",
      "\n",
      "Column Name:  ring-number\n",
      "count     8124\n",
      "unique       3\n",
      "top          o\n",
      "freq      7488\n",
      "Name: ring-number, dtype: object\n",
      "\n",
      "Column Name:  ring-type\n",
      "count     8124\n",
      "unique       5\n",
      "top          p\n",
      "freq      3968\n",
      "Name: ring-type, dtype: object\n",
      "\n",
      "Column Name:  spore-print-color\n",
      "count     8124\n",
      "unique       9\n",
      "top          w\n",
      "freq      2388\n",
      "Name: spore-print-color, dtype: object\n",
      "\n",
      "Column Name:  population\n",
      "count     8124\n",
      "unique       6\n",
      "top          v\n",
      "freq      4040\n",
      "Name: population, dtype: object\n",
      "\n",
      "Column Name:  habitat\n",
      "count     8124\n",
      "unique       7\n",
      "top          d\n",
      "freq      3148\n",
      "Name: habitat, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#See the description of different columns\n",
    "for col in raw_data :\n",
    "    print()\n",
    "    print ('Column Name: ',col)\n",
    "    print(raw_data[col].describe())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Name:  class\n",
      "e    4208\n",
      "p    3916\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Column Name:  cap-shape\n",
      "x    3656\n",
      "f    3152\n",
      "k     828\n",
      "b     452\n",
      "s      32\n",
      "c       4\n",
      "Name: cap-shape, dtype: int64\n",
      "\n",
      "Column Name:  cap-surface\n",
      "y    3244\n",
      "s    2556\n",
      "f    2320\n",
      "g       4\n",
      "Name: cap-surface, dtype: int64\n",
      "\n",
      "Column Name:  cap-color\n",
      "n    2284\n",
      "g    1840\n",
      "e    1500\n",
      "y    1072\n",
      "w    1040\n",
      "b     168\n",
      "p     144\n",
      "c      44\n",
      "u      16\n",
      "r      16\n",
      "Name: cap-color, dtype: int64\n",
      "\n",
      "Column Name:  bruises\n",
      "f    4748\n",
      "t    3376\n",
      "Name: bruises, dtype: int64\n",
      "\n",
      "Column Name:  odor\n",
      "n    3528\n",
      "f    2160\n",
      "y     576\n",
      "s     576\n",
      "a     400\n",
      "l     400\n",
      "p     256\n",
      "c     192\n",
      "m      36\n",
      "Name: odor, dtype: int64\n",
      "\n",
      "Column Name:  gill-attachment\n",
      "f    7914\n",
      "a     210\n",
      "Name: gill-attachment, dtype: int64\n",
      "\n",
      "Column Name:  gill-spacing\n",
      "c    6812\n",
      "w    1312\n",
      "Name: gill-spacing, dtype: int64\n",
      "\n",
      "Column Name:  gill-size\n",
      "b    5612\n",
      "n    2512\n",
      "Name: gill-size, dtype: int64\n",
      "\n",
      "Column Name:  gill-color\n",
      "b    1728\n",
      "p    1492\n",
      "w    1202\n",
      "n    1048\n",
      "g     752\n",
      "h     732\n",
      "u     492\n",
      "k     408\n",
      "e      96\n",
      "y      86\n",
      "o      64\n",
      "r      24\n",
      "Name: gill-color, dtype: int64\n",
      "\n",
      "Column Name:  stalk-shape\n",
      "t    4608\n",
      "e    3516\n",
      "Name: stalk-shape, dtype: int64\n",
      "\n",
      "Column Name:  stalk-root\n",
      "b    3776\n",
      "?    2480\n",
      "e    1120\n",
      "c     556\n",
      "r     192\n",
      "Name: stalk-root, dtype: int64\n",
      "\n",
      "Column Name:  stalk-surface-above-ring\n",
      "s    5176\n",
      "k    2372\n",
      "f     552\n",
      "y      24\n",
      "Name: stalk-surface-above-ring, dtype: int64\n",
      "\n",
      "Column Name:  stalk-surface-below-ring\n",
      "s    4936\n",
      "k    2304\n",
      "f     600\n",
      "y     284\n",
      "Name: stalk-surface-below-ring, dtype: int64\n",
      "\n",
      "Column Name:  stalk-color-above-ring\n",
      "w    4464\n",
      "p    1872\n",
      "g     576\n",
      "n     448\n",
      "b     432\n",
      "o     192\n",
      "e      96\n",
      "c      36\n",
      "y       8\n",
      "Name: stalk-color-above-ring, dtype: int64\n",
      "\n",
      "Column Name:  stalk-color-below-ring\n",
      "w    4384\n",
      "p    1872\n",
      "g     576\n",
      "n     512\n",
      "b     432\n",
      "o     192\n",
      "e      96\n",
      "c      36\n",
      "y      24\n",
      "Name: stalk-color-below-ring, dtype: int64\n",
      "\n",
      "Column Name:  veil-type\n",
      "p    8124\n",
      "Name: veil-type, dtype: int64\n",
      "\n",
      "Column Name:  veil-color\n",
      "w    7924\n",
      "o      96\n",
      "n      96\n",
      "y       8\n",
      "Name: veil-color, dtype: int64\n",
      "\n",
      "Column Name:  ring-number\n",
      "o    7488\n",
      "t     600\n",
      "n      36\n",
      "Name: ring-number, dtype: int64\n",
      "\n",
      "Column Name:  ring-type\n",
      "p    3968\n",
      "e    2776\n",
      "l    1296\n",
      "f      48\n",
      "n      36\n",
      "Name: ring-type, dtype: int64\n",
      "\n",
      "Column Name:  spore-print-color\n",
      "w    2388\n",
      "n    1968\n",
      "k    1872\n",
      "h    1632\n",
      "r      72\n",
      "y      48\n",
      "u      48\n",
      "o      48\n",
      "b      48\n",
      "Name: spore-print-color, dtype: int64\n",
      "\n",
      "Column Name:  population\n",
      "v    4040\n",
      "y    1712\n",
      "s    1248\n",
      "n     400\n",
      "a     384\n",
      "c     340\n",
      "Name: population, dtype: int64\n",
      "\n",
      "Column Name:  habitat\n",
      "d    3148\n",
      "g    2148\n",
      "p    1144\n",
      "l     832\n",
      "u     368\n",
      "m     292\n",
      "w     192\n",
      "Name: habitat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Different values in the columns and its count\n",
    "for col in raw_data :\n",
    "    print()\n",
    "    print ('Column Name: ',col)\n",
    "    print(raw_data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples\n",
      "  cap-shape cap-surface cap-color bruises odor gill-attachment gill-spacing  \\\n",
      "0         x           s         n       t    p               f            c   \n",
      "1         x           s         y       t    a               f            c   \n",
      "2         b           s         w       t    l               f            c   \n",
      "3         x           y         w       t    p               f            c   \n",
      "4         x           s         g       f    n               f            w   \n",
      "\n",
      "  gill-size gill-color stalk-shape   ...   stalk-surface-below-ring  \\\n",
      "0         n          k           e   ...                          s   \n",
      "1         b          k           e   ...                          s   \n",
      "2         b          n           e   ...                          s   \n",
      "3         n          n           e   ...                          s   \n",
      "4         b          k           t   ...                          s   \n",
      "\n",
      "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "0                      w                      w         p          w   \n",
      "1                      w                      w         p          w   \n",
      "2                      w                      w         p          w   \n",
      "3                      w                      w         p          w   \n",
      "4                      w                      w         p          w   \n",
      "\n",
      "  ring-number ring-type spore-print-color population habitat  \n",
      "0           o         p                 k          s       u  \n",
      "1           o         p                 n          n       g  \n",
      "2           o         p                 n          n       m  \n",
      "3           o         p                 k          s       u  \n",
      "4           o         e                 n          a       g  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Labels\n",
      "0    p\n",
      "1    e\n",
      "2    e\n",
      "3    p\n",
      "4    e\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split the file into samples and labels\n",
    "samples = raw_data.drop('class',1)\n",
    "labels = raw_data['class']\n",
    "print('Samples')\n",
    "print(samples[:5])\n",
    "print()\n",
    "print('Labels')\n",
    "print(labels[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the description of data it can be seen that all of the values are categorical values. Thus before initiating training we have to convert them into numerical values. This is done using Label Encoder as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples\n",
      "   cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
      "0          5            2          4        1     6                1   \n",
      "1          5            2          9        1     0                1   \n",
      "2          0            2          8        1     3                1   \n",
      "3          5            3          8        1     6                1   \n",
      "4          5            2          3        0     5                1   \n",
      "\n",
      "   gill-spacing  gill-size  gill-color  stalk-shape   ...     \\\n",
      "0             0          1           4            0   ...      \n",
      "1             0          0           4            0   ...      \n",
      "2             0          0           5            0   ...      \n",
      "3             0          1           5            0   ...      \n",
      "4             1          0           4            1   ...      \n",
      "\n",
      "   stalk-surface-below-ring  stalk-color-above-ring  stalk-color-below-ring  \\\n",
      "0                         2                       7                       7   \n",
      "1                         2                       7                       7   \n",
      "2                         2                       7                       7   \n",
      "3                         2                       7                       7   \n",
      "4                         2                       7                       7   \n",
      "\n",
      "   veil-type  veil-color  ring-number  ring-type  spore-print-color  \\\n",
      "0          0           2            1          4                  2   \n",
      "1          0           2            1          4                  3   \n",
      "2          0           2            1          4                  3   \n",
      "3          0           2            1          4                  2   \n",
      "4          0           2            1          0                  3   \n",
      "\n",
      "   population  habitat  \n",
      "0           3        5  \n",
      "1           2        1  \n",
      "2           2        3  \n",
      "3           3        5  \n",
      "4           0        1  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Labels\n",
      "[1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lb=preprocessing.LabelEncoder() #Initating the encoder\n",
    "\n",
    "#Encoding the features(columns of samples)\n",
    "for cols in samples.columns:\n",
    "    samples[cols] = lb.fit_transform(samples[cols])\n",
    "\n",
    "print('Samples')\n",
    "print(samples[:5])\n",
    "print()\n",
    "\n",
    "#Encoding the labels\n",
    "labels=lb.fit_transform(labels)\n",
    "print('Labels')\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that ecoding is done it is time to split the data for training , validation and testing purposes. This is done so that a model does not overfit to the training data. Validation data is done so as to select the type of models which perform good in validation set after having trained in training set. But still there is one more problem which arises that is bleeding of the validation data into the training data. This happens when one tries to maximize the performance in validation set by tweaking the parameters in training set. Thus the model tries to indirectly fit the validation set.\n",
    "\n",
    "Thus the need for a set which can be used for testing and which is isolated from training is required. Performance on this set will be the final deciding factor for selection of the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data count : 5686\n",
      "Validation data count : 1219\n",
      "Testing data count : 1219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # for splitting the data\n",
    "\n",
    "# Normally data is split into 70,15,15 % for training , validation and testing respectivlely\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(samples, labels, test_size=0.30, random_state=42)\n",
    "X_valid, X_test, Y_valid, Y_test = train_test_split(X_valid, Y_valid, test_size=0.50, random_state=42)\n",
    "print('Training data count : {}'.format(X_train.count()[0]))\n",
    "print('Validation data count : {}'.format(X_valid.count()[0]))\n",
    "print('Testing data count : {}'.format(X_test.count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Now lets set a benchmark model which we can compare with other models. Since this is a binary classification problem the simplest model would be when the model classifies each sample as poisonous i.e. 1. This will cause roughly half of the samples to be classified correclty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Benchmark model\n",
    "#Making predictions as 1(poisonous)\n",
    "Y_pred =np.ones_like(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.490566\n",
      "Accuracy: 0.490566\n",
      "Recall: 1.000000\n",
      "F1 score: 0.658228\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {0:2f}'.format(metrics.precision_score(Y_test,Y_pred)))\n",
    "print('Accuracy: {0:2f}'.format(metrics.accuracy_score(Y_test,Y_pred)))\n",
    "print('Recall: {0:2f}'.format(metrics.recall_score(Y_test,Y_pred)))\n",
    "print('F1 score: {0:2f}'.format(metrics.f1_score(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus from above it is certain that the worst a model can perform would have these values. For our model it is important to absolutely classify poisonous correctly. Thus importance will be given to precision and F1 score rather then accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training following models are considered :\n",
    "1) Logistic Regression\n",
    "2) Decision Tree Classifier\n",
    "3) Random Forest\n",
    "4) Support Vector Machines\n",
    "5) AdaBoost Classifier\n",
    "6) xgBoost Classifier\n",
    "7) Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "models ={'Logistic Regression':LogisticRegression(),'Decision Tree Classifier':DecisionTreeClassifier(),\n",
    "         'Random Forest':RandomForestClassifier(),'Support Vector Machines':SVC(),'AdaBoost Classifier':AdaBoostClassifier(),\n",
    "         'Stochastic Gradient Descent':SGDClassifier(),'XGBoost Classifiier':XGBClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.914035</td>\n",
       "      <td>0.935368</td>\n",
       "      <td>0.893654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.938474</td>\n",
       "      <td>0.935843</td>\n",
       "      <td>0.933447</td>\n",
       "      <td>0.938250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost Classifiier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Models  Accuracy  F1-score  Precision    Recall\n",
       "0     Decision Tree Classifier  1.000000  1.000000   1.000000  1.000000\n",
       "1                Random Forest  1.000000  1.000000   1.000000  1.000000\n",
       "2      Support Vector Machines  1.000000  1.000000   1.000000  1.000000\n",
       "3  Stochastic Gradient Descent  0.919606  0.914035   0.935368  0.893654\n",
       "4          Logistic Regression  0.938474  0.935843   0.933447  0.938250\n",
       "5          XGBoost Classifiier  1.000000  1.000000   1.000000  1.000000\n",
       "6          AdaBoost Classifier  1.000000  1.000000   1.000000  1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training models on training set and performance evluation on validation set\n",
    "scores_precision=[]\n",
    "scores_acc=[]\n",
    "scores_recall=[]\n",
    "scores_f1score=[]\n",
    "names=[]\n",
    "for name,model in models.items():\n",
    "    model.fit(X_train,Y_train)\n",
    "    names.append(name)\n",
    "    precision=metrics.precision_score(Y_valid,model.predict(X_valid))\n",
    "    scores_precision.append(precision)\n",
    "    acc=metrics.accuracy_score(Y_valid,model.predict(X_valid))\n",
    "    scores_acc.append(acc)\n",
    "    recall=metrics.recall_score(Y_valid,model.predict(X_valid))\n",
    "    scores_recall.append(recall)\n",
    "    f1score=metrics.f1_score(Y_valid,model.predict(X_valid))\n",
    "    scores_f1score.append(f1score)\n",
    "   \n",
    "    dataframe = pd.DataFrame({'Models':names,'Precision':scores_precision,'F1-score':scores_f1score,\n",
    "                              'Accuracy':scores_acc,'Recall':scores_recall})\n",
    "    \n",
    "cols = list(dataframe)\n",
    "# move the column to head of list using index, pop and insert\n",
    "cols.insert(0, cols.pop(cols.index('Models')))\n",
    "dataframe = dataframe.ix[:, cols]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above it can be concluded that Stochastic Gradient Descent and Logistic regression performs worst in this dataset classification. And rest of the classifiers perform exceptionally well in classification. As previously specified the model will be chosen based on the Precision score and F1 score. Thus any of the following models could be used : Decision Tree Classifier, AdaBoost Classifier, Support Vector Machines, Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models train on a large number of features. And may be not all features contribute to the classification. In this dataset and classification the number of features used are 22. Thus to check weather these features actually conrtibute to the classification we will use PCA(Principle Component Analysis) available from sklearn.decomposition . We shall first import the PCA.Then run it with all the components, plot a bar graph. Calculate how many features are required to maintain 99.5% of data variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 features variance ratio is : [ 0.33878807  0.16511952  0.12277489  0.06928601  0.05836053]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA #Importing PCA\n",
    "pca=PCA(n_components=22) # Initializing PCA\n",
    "pca.fit(X_train) \n",
    "var_ratio=pca.explained_variance_ratio_\n",
    "print('First 5 features variance ratio is :',var_ratio[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAI4CAYAAAB3OR9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec9fa9edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot to show fetures contribution to variance\n",
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    plt.bar(range(22), var_ratio, alpha=0.5, align='center',\n",
    "            label='Individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 features are required to contain 99.64669109357057 % of variance in data\n"
     ]
    }
   ],
   "source": [
    "#Now calculating the number of features required to contain 99.5% of the data's variance\n",
    "add =0.0\n",
    "count =0\n",
    "for i in range(22):\n",
    "    count+= 1\n",
    "    add+= var_ratio[i]\n",
    "    if ((add/1.0)*100 >99.5) :\n",
    "        break\n",
    "        \n",
    "print('{} features are required to contain {} % of variance in data'.format(count,add*100))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have determined that 16 features are enough to contain 99.5% of variance, we will transform the data into its 16 principle components and retrain the models on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.87159390e-01  -3.05939069e-01   1.67521591e+00  -3.84647670e+00\n",
      "    5.58736483e+00   1.09488269e+00  -3.76881442e-01   2.00618095e+00\n",
      "   -5.79328810e-01   4.64266301e-01   3.62531621e-02  -1.41577899e+00\n",
      "    1.84036546e-01   1.16927089e+00  -6.10717069e-01   1.59486394e-01]\n",
      " [ -2.69236937e+00  -2.28748744e+00   5.70686038e-01  -2.77025414e+00\n",
      "   -9.50369499e-01   4.37899764e-01   6.64031960e-01   1.09576837e+00\n",
      "    2.32572869e-01   1.43347650e+00  -5.63360319e-01   4.61922163e-02\n",
      "   -3.82590611e-01  -1.47726217e-01  -2.21734284e-01  -1.77441561e-01]\n",
      " [ -3.76567093e+00   1.09484606e+00   5.82870184e+00   7.65118748e-02\n",
      "   -2.21640613e-01   1.49663300e+00   6.54384282e-01  -2.76716579e+00\n",
      "   -2.07732923e+00   7.64224585e-01   1.50949733e-01  -2.03761633e-02\n",
      "    8.80422377e-02   5.62436832e-02   3.46198297e-01  -1.49182664e-02]\n",
      " [ -2.20470771e+00   5.17564318e+00  -3.34954134e+00  -1.52603668e+00\n",
      "    8.79615852e-01  -1.70609058e-01   2.21010198e+00  -1.39662335e-01\n",
      "    4.79019111e-02  -8.49995068e-01   1.90617225e+00  -1.87337959e-01\n",
      "   -3.75694125e-01   1.54786461e-03  -1.91938641e-01  -4.03011624e-02]\n",
      " [  6.97733576e+00  -1.22392026e+00  -2.97208618e-01  -2.59147516e-01\n",
      "   -3.23650949e+00   7.87349506e-01   1.28218697e+00   3.01086740e-01\n",
      "   -9.38477543e-01  -1.02932524e+00  -8.84404243e-02  -4.74457234e-01\n",
      "    5.09494661e-01  -3.51536192e-02  -6.49710005e-02   1.05699128e-01]]\n"
     ]
    }
   ],
   "source": [
    "#Transforming into 16 principle components\n",
    "pca=PCA(n_components=16) # Initializing PCA\n",
    "pca.fit(X_train)\n",
    "X_train_pca= pca.transform(X_train)\n",
    "X_valid_pca= pca.transform(X_valid)# for validation purposes\n",
    "X_test_pca=pca.transform(X_test)\n",
    "print(X_train_pca[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now let us re-train all the models with the transformed features and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.990156</td>\n",
       "      <td>0.989708</td>\n",
       "      <td>0.989708</td>\n",
       "      <td>0.989708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.998359</td>\n",
       "      <td>0.998282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.864643</td>\n",
       "      <td>0.862843</td>\n",
       "      <td>0.837097</td>\n",
       "      <td>0.890223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.880230</td>\n",
       "      <td>0.873264</td>\n",
       "      <td>0.884007</td>\n",
       "      <td>0.862779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost Classifiier</td>\n",
       "      <td>0.991797</td>\n",
       "      <td>0.991364</td>\n",
       "      <td>0.998261</td>\n",
       "      <td>0.984563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.966366</td>\n",
       "      <td>0.964927</td>\n",
       "      <td>0.962457</td>\n",
       "      <td>0.967410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Models  Accuracy  F1-score  Precision    Recall\n",
       "0     Decision Tree Classifier  0.990156  0.989708   0.989708  0.989708\n",
       "1                Random Forest  0.998359  0.998282   1.000000  0.996569\n",
       "2      Support Vector Machines  1.000000  1.000000   1.000000  1.000000\n",
       "3  Stochastic Gradient Descent  0.864643  0.862843   0.837097  0.890223\n",
       "4          Logistic Regression  0.880230  0.873264   0.884007  0.862779\n",
       "5          XGBoost Classifiier  0.991797  0.991364   0.998261  0.984563\n",
       "6          AdaBoost Classifier  0.966366  0.964927   0.962457  0.967410"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retraining the models on X_train_pca features and validating on X_valid_pca\n",
    "scores_precision=[]\n",
    "scores_acc=[]\n",
    "scores_recall=[]\n",
    "scores_f1score=[]\n",
    "names=[]\n",
    "for name,model in models.items():\n",
    "    model.fit(X_train_pca,Y_train)\n",
    "    names.append(name)\n",
    "    precision=metrics.precision_score(Y_valid,model.predict(X_valid_pca))\n",
    "    scores_precision.append(precision)\n",
    "    acc=metrics.accuracy_score(Y_valid,model.predict(X_valid_pca))\n",
    "    scores_acc.append(acc)\n",
    "    recall=metrics.recall_score(Y_valid,model.predict(X_valid_pca))\n",
    "    scores_recall.append(recall)\n",
    "    f1score=metrics.f1_score(Y_valid,model.predict(X_valid_pca))\n",
    "    scores_f1score.append(f1score)\n",
    "    dataframe = pd.DataFrame({'Models':names,'Precision':scores_precision,'F1-score':scores_f1score,\n",
    "                              'Accuracy':scores_acc,'Recall':scores_recall})\n",
    "    \n",
    "cols = list(dataframe)\n",
    "# move the column to head of list using index, pop and insert\n",
    "cols.insert(0, cols.pop(cols.index('Models')))\n",
    "dataframe = dataframe.ix[:, cols]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "From the results above it clearly shows that without any optimization the best models for this scenario are SVM and random forest followed by XGBoost, Decision Tree Classifier and AdaBoost Classifier.Logistic Classifier and Stochastic Gradient Descent perform the worst. Thus we will select SVM, Random Forest, XGBoost, Decision Tree Classifier and AdaBoost Classifier for final testing in the test data set. ALso we will try to optimize them with the help of Grid Search CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing Grid Search CV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer,precision_score\n",
    "\n",
    "#Initializing few models for Grid Search CV\n",
    "svr =SVC()\n",
    "ran=RandomForestClassifier()\n",
    "xgb=XGBClassifier()\n",
    "ada=AdaBoostClassifier()\n",
    "dt=DecisionTreeClassifier()\n",
    "\n",
    "#parameters for Support Vector Machine\n",
    "parameters_svr = {'C':[0.1,0.3,0.9,1.0,3.0,9.0,10.0],\n",
    "                  'kernel':('linear','rbf'),\n",
    "                  'random_state':[1,42,56,32,15]}\n",
    "#parameters for Random_forest\n",
    "parameters_ran = {'n_estimators':[2,5,7,10,12,15,18,20],'random_state':[1,42,56,32,15]}\n",
    "\n",
    "#parameters for XG Boost Classifier\n",
    "parameters_xgb = {'learning_rate':[0.01,0.03,0.09,0.1,0.3,0.9,1],'booster':('gbtree','gblinear','dart'),\n",
    "                  'random_state':[1,15,2,3,48,42]}\n",
    "\n",
    "#parameters for Decision Tree Classifier\n",
    "parameters_dt = {'min_samples_split':[2,7,10], 'random_state':[1,42,56,32,15]}\n",
    "\n",
    "#parameters for AdaBoost Classifier\n",
    "parameters_ada= {'learning_rate':[0.01,0.03,0.09,0.1,0.3,0.9,1],'n_estimators':[10,30,50,70],\n",
    "                'random_state':[1,42,56,32,15]}\n",
    "\n",
    "#Defining precision as the factor for comparision\n",
    "scorer = make_scorer(precision_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM best Parameters: \n",
      "{'random_state': 1, 'C': 3.0, 'kernel': 'rbf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating best parameters for SVM\n",
    "clf = GridSearchCV(svr,parameters_svr,scoring=scorer)\n",
    "clf.fit(X_train_pca,Y_train)\n",
    "print('SVM best Parameters: ')\n",
    "print(clf.best_params_)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest best Parameters: \n",
      "{'random_state': 1, 'n_estimators': 7}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating best parameters for Random Forest\n",
    "clf = GridSearchCV(ran,parameters_ran,scoring=scorer)\n",
    "clf.fit(X_train_pca,Y_train)\n",
    "print('Random Forest best Parameters: ')\n",
    "print(clf.best_params_)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost best Parameters: \n",
      "{'learning_rate': 0.9, 'random_state': 1, 'booster': 'gbtree'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating best parameters for xgBoost Classifier\n",
    "clf = GridSearchCV(xgb,parameters_xgb,scoring=scorer)\n",
    "clf.fit(X_train_pca,Y_train)\n",
    "print('XG Boost best Parameters: ')\n",
    "print(clf.best_params_)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree best Parameters: \n",
      "{'random_state': 42, 'min_samples_split': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating best parameters for DecisionTree Classifier\n",
    "clf = GridSearchCV(dt,parameters_dt,scoring=scorer)\n",
    "clf.fit(X_train_pca,Y_train)\n",
    "print('DecisionTree best Parameters: ')\n",
    "print(clf.best_params_)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best Parameters: \n",
      "{'learning_rate': 1, 'random_state': 1, 'n_estimators': 70}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating best parameters for AdaBoost Classifier\n",
    "clf = GridSearchCV(ada,parameters_ada,scoring=scorer)\n",
    "clf.fit(X_train_pca,Y_train)\n",
    "print('AdaBoost best Parameters: ')\n",
    "print(clf.best_params_)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Parameter optimization takes very long time (about 15 min for SVM, Adaboost, xgboost) depending on the processing power. Models like Decision Trees and Random Forest take minimal time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have optimal parameters  from the set of parameters that we defined, let us re-train these models on the opitmal parameters and then test them with test set which we have previously kept aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.988860</td>\n",
       "      <td>0.988014</td>\n",
       "      <td>0.989708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XG Boost Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.977851</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.980969</td>\n",
       "      <td>0.972556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Models  Accuracy  F1-score  Precision    Recall\n",
       "0  Decision Tree Classifier  0.989336  0.988860   0.988014  0.989708\n",
       "1             Random Forest  1.000000  1.000000   1.000000  1.000000\n",
       "2   Support Vector Machines  1.000000  1.000000   1.000000  1.000000\n",
       "3       XG Boost Classifier  1.000000  1.000000   1.000000  1.000000\n",
       "4       AdaBoost Classifier  0.977851  0.976744   0.980969  0.972556"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_optimal={'Random Forest':RandomForestClassifier(n_estimators=7,random_state=1),\n",
    "               'Support Vector Machines':SVC(kernel='rbf',random_state=1,C=3),\n",
    "               'XG Boost Classifier':XGBClassifier(random_state=1, booster='gbtree', learning_rate= 0.9),\n",
    "               'Decision Tree Classifier': DecisionTreeClassifier(min_samples_split= 2, random_state= 42),\n",
    "               'AdaBoost Classifier': AdaBoostClassifier(random_state= 1, n_estimators= 70, learning_rate= 1)}\n",
    "scores_precision=[]\n",
    "scores_acc=[]\n",
    "scores_recall=[]\n",
    "scores_f1score=[]\n",
    "names=[]\n",
    "for name,model in model_optimal.items():\n",
    "    model.fit(X_train_pca,Y_train)\n",
    "    names.append(name)\n",
    "    precision=metrics.precision_score(Y_valid,model.predict(X_valid_pca))\n",
    "    scores_precision.append(precision)\n",
    "    acc=metrics.accuracy_score(Y_valid,model.predict(X_valid_pca))\n",
    "    scores_acc.append(acc)\n",
    "    recall=metrics.recall_score(Y_valid,model.predict(X_valid_pca))\n",
    "    scores_recall.append(recall)\n",
    "    f1score=metrics.f1_score(Y_valid,model.predict(X_valid_pca))\n",
    "    scores_f1score.append(f1score)\n",
    "    dataframe = pd.DataFrame({'Models':names,'Precision':scores_precision,'F1-score':scores_f1score,\n",
    "                              'Accuracy':scores_acc,'Recall':scores_recall})\n",
    "    \n",
    "cols = list(dataframe)\n",
    "# move the column to head of list using index, pop and insert\n",
    "cols.insert(0, cols.pop(cols.index('Models')))\n",
    "dataframe = dataframe.ix[:, cols]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that by optimizing there is mariginal increase in the performance of the models as previously models were already giving very high performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets test the models on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.997539</td>\n",
       "      <td>0.997498</td>\n",
       "      <td>0.995008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.998359</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XG Boost Classifier</td>\n",
       "      <td>0.999180</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.983593</td>\n",
       "      <td>0.983221</td>\n",
       "      <td>0.986532</td>\n",
       "      <td>0.979933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Models  Accuracy  F1-score  Precision    Recall\n",
       "0  Decision Tree Classifier  0.997539  0.997498   0.995008  1.000000\n",
       "1             Random Forest  0.998359  0.998325   1.000000  0.996656\n",
       "2   Support Vector Machines  1.000000  1.000000   1.000000  1.000000\n",
       "3       XG Boost Classifier  0.999180  0.999163   1.000000  0.998328\n",
       "4       AdaBoost Classifier  0.983593  0.983221   0.986532  0.979933"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming X_test to PCA components\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "\n",
    "scores_precision=[]\n",
    "scores_acc=[]\n",
    "scores_recall=[]\n",
    "scores_f1score=[]\n",
    "names=[]\n",
    "for name,model in model_optimal.items():\n",
    "    model.fit(X_train_pca,Y_train)\n",
    "    names.append(name)\n",
    "    precision=metrics.precision_score(Y_test,model.predict(X_test_pca))\n",
    "    scores_precision.append(precision)\n",
    "    acc=metrics.accuracy_score(Y_test,model.predict(X_test_pca))\n",
    "    scores_acc.append(acc)\n",
    "    recall=metrics.recall_score(Y_test,model.predict(X_test_pca))\n",
    "    scores_recall.append(recall)\n",
    "    f1score=metrics.f1_score(Y_test,model.predict(X_test_pca))\n",
    "    scores_f1score.append(f1score)\n",
    "    dataframe = pd.DataFrame({'Models':names,'Precision':scores_precision,'F1-score':scores_f1score,\n",
    "                              'Accuracy':scores_acc,'Recall':scores_recall})\n",
    "    \n",
    "cols = list(dataframe)\n",
    "# move the column to head of list using index, pop and insert\n",
    "cols.insert(0, cols.pop(cols.index('Models')))\n",
    "dataframe = dataframe.ix[:, cols]\n",
    "dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Thus it can be concluded that best models for classification are : Support Vector Machines, Random Forest and xgBoost for when we have applied PCA. But training time wise , it can be said that Decision tree is the fastest and SVM takes the most time for training. But overall if training time is not a constraint then SVM  could be said to be the best model for classification for this type of problem. SVM has been consistently giving outstanding performance in this problem. It has perfect results in all areas in all types of tesing (validation , testing). Thus it could be said to be the best model If training time is a constraint then Random Forest should be the next best classifier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Code Reference :\n",
    "\n",
    "https://www.kaggle.com/nirajvermafcb/comparing-various-ml-models-roc-curve-comparison\n",
    "\n",
    "\n",
    "https://www.kaggle.com/monkeydunkey/a-comparison-of-few-ml-models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
